{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frgWI6KFbYvw",
        "outputId": "80c5a19e-50cb-42a6-f1a0-aef950d9f4b2"
      },
      "outputs": [],
      "source": [
        "!pip install kagglehub\n",
        "!pip install segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tSjlBR9bq-1",
        "outputId": "a4782afd-2683-4680-c498-228c4275f2af"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"abdallahwagih/kvasir-dataset-for-classification-and-segmentation\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNiBrcoxd-aZ",
        "outputId": "2cc6d32f-327c-42b8-a102-e5928e798fee"
      },
      "outputs": [],
      "source": [
        "mv /root/.cache/kagglehub/datasets/abdallahwagih/kvasir-dataset-for-classification-and-segmentation/versions/1 ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "VUDRythmcl26"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "v308lpjtdw2v"
      },
      "outputs": [],
      "source": [
        "Image_path = '/content/1/kvasir-seg/Kvasir-SEG/images'\n",
        "Mask_path = '/content/1/kvasir-seg/Kvasir-SEG/masks'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQFUwBfXemvo",
        "outputId": "bd14858d-6ce5-49f5-c869-6746efe70480"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "u2pAi8qGe0a7"
      },
      "outputs": [],
      "source": [
        "class segmentationDataset(Dataset):\n",
        "  def __init__(self, image_paths: list, mask_paths: list, transform=None):\n",
        "    self.image_paths = image_paths\n",
        "    self.mask_paths = mask_paths\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image = cv2.imread(self.image_paths[idx])\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
        "    image = cv2.resize(image, (256, 256))\n",
        "    image = image.astype(np.float32)\n",
        "    image /= 255.0\n",
        "\n",
        "    mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
        "    mask = cv2.resize(mask, (256, 256))\n",
        "    mask = mask.astype('float32')\n",
        "    mask /= 255.0\n",
        "    mask = np.expand_dims(mask, axis=0)\n",
        "\n",
        "    image = torch.tensor(image).permute(2, 0, 1)\n",
        "    mask = torch.tensor(mask)\n",
        "\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "2r_5V_xGe6xu"
      },
      "outputs": [],
      "source": [
        "image_paths = sorted(glob(os.path.join(Image_path, '*jpg')))\n",
        "mask_paths = sorted(glob(os.path.join(Mask_path, '*jpg')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ezzF7Zsjyzs",
        "outputId": "f9ef3287-eac1-4cf6-ac80-27e6818c1264"
      },
      "outputs": [],
      "source": [
        "train_images, test_images, train_mask, test_mask = train_test_split(image_paths, mask_paths, test_size=0.3, random_state=42)\n",
        "\n",
        "len(train_images), len(test_images), len(train_mask), len(test_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SulZrcOwj1T3",
        "outputId": "672fae80-67c6-4862-c16e-1ff01190f0c4"
      },
      "outputs": [],
      "source": [
        "train_dataset = segmentationDataset(train_images, train_mask)\n",
        "test_dataset = segmentationDataset(test_images, test_mask)\n",
        "\n",
        "len(train_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WDdioT8j1WJ",
        "outputId": "0c1883d0-33ac-4d83-c078-cdbed90b1075"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "len(train_loader), len(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "9qXyNHWij1Ye"
      },
      "outputs": [],
      "source": [
        "image, mask = train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cnzX-i9j1cI",
        "outputId": "7277cdc2-250c-4aaf-c5e8-ee6301e272be"
      },
      "outputs": [],
      "source": [
        "print(image.size())\n",
        "print(mask.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "bMjffMxYlyRC",
        "outputId": "0100b751-85d3-41dd-ef6a-1949eb12e4b7"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image.permute(1, 2, 0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "Vsj3TpUdmS5c",
        "outputId": "ff060372-13af-4a88-a079-b75a01cb07de"
      },
      "outputs": [],
      "source": [
        "plt.imshow(mask.permute(1,2,0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWHHdys3ndn4"
      },
      "source": [
        "## *Model*\n",
        "\n",
        "https://pypi.org/project/segmentation-models-pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "4WBDDbKzmXWL"
      },
      "outputs": [],
      "source": [
        "model = smp.Unet(encoder_name='resnet50', encoder_weights='imagenet', in_channels=3, classes=1)\n",
        "model = model.to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0ve9uo-oPGQ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVKjwn95oLup",
        "outputId": "e13c4256-c2b2-4641-c6bc-43ecf4bf77b0"
      },
      "outputs": [],
      "source": [
        "best_loss = float('inf')\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  train_loss = 0.0\n",
        "\n",
        "  for images, masks in train_loader:\n",
        "    images = images.to(device)\n",
        "    masks = masks.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, masks)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  model.eval()\n",
        "  test_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, masks in test_loader:\n",
        "      images = images.to(device)\n",
        "      masks = masks.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, masks)\n",
        "      test_loss += loss.item()\n",
        "\n",
        "  train_loss /= len(train_loader)\n",
        "  test_loss /= len(test_loader)\n",
        "\n",
        "  print(f'epoch: {epoch+1}/{num_epochs}, train loss: {train_loss}, test loss: {test_loss}')\n",
        "\n",
        "  if test_loss < best_loss:\n",
        "    best_loss = test_loss\n",
        "    torch.save(model.state_dict(), 'best_model.pth')\n",
        "    print('Model saved!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwOD87o_st1n"
      },
      "source": [
        "## Visualizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "JzvoAxO2p6rB"
      },
      "outputs": [],
      "source": [
        "def visualize_predictions(model, image_path, mask_image, device):\n",
        "  image = cv2.imread(image_path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
        "  image = cv2.resize(image, (256, 256))\n",
        "  image = image.astype(np.float32)\n",
        "  image /= 255.0\n",
        "\n",
        "  mask_image = cv2.imread(mask_image)\n",
        "  mask_image = cv2.cvtColor(mask_image, cv2.COLOR_BGRA2RGB)\n",
        "  mask_image = cv2.resize(mask_image, (256, 256))\n",
        "  mask_image = mask_image.astype(np.float32)\n",
        "  mask_image /= 255.0\n",
        "\n",
        "  image_tensor = torch.tensor(image).permute(2, 0, 1).unsqueeze(0)\n",
        "  image_tensor = image_tensor.to(device)\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    output = model(image_tensor)\n",
        "    output = torch.sigmoid(output).cpu().squeeze().numpy()\n",
        "    output = (output > 0.5).astype(np.uint8)\n",
        "\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.subplot(1, 4, 1)\n",
        "  plt.title('Image')\n",
        "  plt.imshow(image)\n",
        "\n",
        "  plt.subplot(1, 4, 2)\n",
        "  plt.title('generatend Mask')\n",
        "  plt.imshow(output)\n",
        "\n",
        "  plt.subplot(1, 4, 3)\n",
        "  plt.title('original Mask')\n",
        "  plt.imshow(mask_image)\n",
        "\n",
        "  plt.subplot(1,4 , 4)\n",
        "  plt.title('overall visual')\n",
        "  plt.imshow(image)\n",
        "  plt.imshow(output, cmap='jet', alpha=0.5)\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3mTqy3LudEb",
        "outputId": "67cf3ff4-efd5-4bae-9243-03419313ebc3"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('best_model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "9K5GDaOBufbe",
        "outputId": "1e74a3f7-6cba-47f6-a34d-4a4014cc0912"
      },
      "outputs": [],
      "source": [
        "image_name = 'cju0rx1idathl0835detmsp84.jpg'\n",
        "sample_image = '/content/1/kvasir-seg/Kvasir-SEG/images/'+image_name\n",
        "mask_image = '/content/1/kvasir-seg/Kvasir-SEG/masks/'+image_name\n",
        "visualize_predictions(model, sample_image, mask_image, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
